{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import sklearn.ensemble\n",
    "from anchor import utils\n",
    "from anchor import anchor_tabular\n",
    "import pandas as pd\n",
    "import xaibenchmark as xb\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# make sure you have adult/adult.data inside dataset_folder\n",
    "dataset_folder = '../data/'\n",
    "dataset = utils.load_dataset('adult', balance=True, dataset_folder=dataset_folder, discretize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Train 0.9350338780390594\nTest 0.8489483747609943\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=50, n_jobs=5)\n",
    "rf.fit(dataset.train, dataset.labels_train)\n",
    "print('Train', sklearn.metrics.accuracy_score(dataset.labels_train, rf.predict(dataset.train)))\n",
    "print('Test', sklearn.metrics.accuracy_score(dataset.labels_test, rf.predict(dataset.test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "### Implementation of Anchors Explainer onto base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class AnchorsExplainer(xb.Explainer):\n",
    "    \n",
    "    def __init__(self, dataset, pathToData):\n",
    "        \n",
    "        self.explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "            dataset.class_names,\n",
    "            dataset.feature_names,\n",
    "            dataset.train,\n",
    "            dataset.categorical_names)\n",
    "        self.dataset = dataset   \n",
    "        self.data = pd.read_csv(pathToData, sep=',')\n",
    "        \n",
    "    def explain_instance(self, instance, predictor, threshold=0.95):\n",
    "        self.explanation = self.explainer.explain_instance(instance, predictor, threshold=threshold)\n",
    "        self.instance = instance   \n",
    "        return self.explanation\n",
    "    \n",
    "    @xb.metric\n",
    "    def coverage(self):\n",
    "        if hasattr(self, 'explanation'):\n",
    "            return self.explanation.coverage()\n",
    "    \n",
    "    @xb.metric\n",
    "    def precision(self):\n",
    "        if hasattr(self, 'explanation'):\n",
    "            return self.explanation.precision()\n",
    "        \n",
    "    @xb.metric\n",
    "    def balance_data_train(self):\n",
    "        return np.mean(self.dataset.labels_train)\n",
    "    \n",
    "    @xb.metric\n",
    "    def balance_data_dev(self):\n",
    "        return np.mean(self.dataset.labels_validation)    \n",
    "    \n",
    "    @xb.metric\n",
    "    def balance_data_test(self):\n",
    "        return np.mean(self.dataset.labels_test)\n",
    "    \n",
    "    @xb.metric\n",
    "    def balance_Explanation(self):\n",
    "        if hasattr(self, 'explanation'):\n",
    "            \n",
    "            # Use original labels from data (not reduced ones by Anchor)\n",
    "            labels = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"country\", \"label\"]\n",
    "            examples_in_explanation_area = 0\n",
    "            examples_positive_label = 0\n",
    "            # print(self.explanation.names())\n",
    "            \n",
    "            # loop over all data elements\n",
    "            for i in range(0,len(self.data)):\n",
    "                correct_features = True\n",
    "                \n",
    "                # check whether the element is in the area of the explanation\n",
    "                for feature in self.explanation.names():\n",
    "                    \n",
    "                    # separately handle non-categorical features\n",
    "                    if \"Age\" in feature:\n",
    "                        continue\n",
    "                    elif \"Capital Gain\" in feature:\n",
    "                        continue\n",
    "                    elif \"Hours per week\" in feature:\n",
    "                        continue\n",
    "                        \n",
    "                    # identify feature and categorical value in explanation and compare to the value of the element\n",
    "                    else:\n",
    "                        feature2 = feature.replace(\" \", \"-\")\n",
    "                        feature_name, value = feature2.split(\"-=-\")\n",
    "                        index = labels.index(feature_name.lower())\n",
    "                        if str(self.data.iat[i,index]).strip() != str(value).strip(): \n",
    "                            # print(\"First index: \", str(self.data.iat[i,index]).strip(), \"Second Index\" , str(value).strip(), \"Data \", self.data.iloc[[i]])\n",
    "                            correct_features = False\n",
    "                            break\n",
    "                            \n",
    "                # if the element is in the explanation's area, count it for balance calculation\n",
    "                if correct_features:\n",
    "                    examples_in_explanation_area += 1\n",
    "                    if self.data.iat[i,14].strip() == \">50K\":\n",
    "                        examples_positive_label += 1\n",
    "                                \n",
    "            if examples_positive_label == 0: return 0   # TODO Capital Loss = 2\n",
    "            return examples_positive_label / examples_in_explanation_area\n",
    "            \n",
    "    @xb.metric\n",
    "    def balance_explanation_train(self):\n",
    "        if hasattr(self, 'explanation'):\n",
    "            fit_anchor = np.where(np.all(self.dataset.train[:, self.explanation.features()] == \n",
    "                                         self.instance[self.explanation.features()], axis=1))[0]\n",
    "            return np.mean(self.dataset.labels_train[fit_anchor])\n",
    "        \n",
    "    @xb.metric\n",
    "    def balance_explanation_dev(self):\n",
    "        if hasattr(self, 'explanation'):\n",
    "            fit_anchor = np.where(np.all(self.dataset.validation[:, self.explanation.features()] == \n",
    "                                         self.instance[self.explanation.features()], axis=1))[0]\n",
    "            return np.mean(self.dataset.labels_validation[fit_anchor])\n",
    "        \n",
    "    @xb.metric\n",
    "    def balance_explanation_test(self):\n",
    "        if hasattr(self, 'explanation'):\n",
    "            fit_anchor = np.where(np.all(self.dataset.test[:, self.explanation.features()] == \n",
    "                                         self.instance[self.explanation.features()], axis=1))[0]\n",
    "            return np.mean(self.dataset.labels_test[fit_anchor])\n",
    "        \n",
    "    @xb.metric\n",
    "    def balance_model_train(self):\n",
    "        return\n",
    "    \n",
    "    @xb.metric\n",
    "    def balance_model_train(self):\n",
    "        return\n",
    "    \n",
    "    @xb.metric\n",
    "    def balance_model_train(self):\n",
    "        return\n",
    "    \n",
    "    @xb.utility\n",
    "    def get_neighborhood_instances(self): \n",
    "        if hasattr(self, 'explanation'):\n",
    "            fit_anchor = np.where(np.all(self.dataset.train[:, self.explanation.features()] == \n",
    "                                         self.instance[self.explanation.features()], axis=1))[0]\n",
    "            return self.dataset.train[fit_anchor]\n",
    "        return []\n",
    "    \n",
    "    @xb.utility\n",
    "    def get_explained_instance(self):\n",
    "        return self.instance\n",
    "    \n",
    "    @xb.utility\n",
    "    def distance(self, x, y):\n",
    "        return np.linalg.norm(x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Usage of implemented explainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['Education = Bachelors', 'Relationship = Husband', 'Race = White', 'Country = United-States', '28.00 < Age <= 37.00', 'Marital Status = Married-civ-spouse', 'Workclass = Private']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# instantiate anchors explainer\n",
    "exp = AnchorsExplainer(dataset ,\"../data/adult/adult.data\")\n",
    "explanation = exp.explain_instance(dataset.test[50], rf.predict, threshold=0.95)\n",
    "print(explanation.names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['Age',\n 'Workclass',\n 'Education',\n 'Marital Status',\n 'Occupation',\n 'Relationship',\n 'Race',\n 'Sex',\n 'Capital Gain',\n 'Capital Loss',\n 'Hours per week',\n 'Country']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 55
    }
   ],
   "source": [
    "# Test area\n",
    "dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['balance_Explanation',\n 'balance_data_dev',\n 'balance_data_test',\n 'balance_data_train',\n 'balance_explanation_dev',\n 'balance_explanation_test',\n 'balance_explanation_train',\n 'balance_model_train',\n 'coverage',\n 'precision']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 56
    }
   ],
   "source": [
    "# get all currently defined metrics\n",
    "exp.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{('balance_Explanation', 0.7256970610399397),\n ('balance_data_dev', 0.4968112244897959),\n ('balance_data_test', 0.49776927979604846),\n ('balance_data_train', 0.5006775607811877),\n ('balance_explanation_dev', 0.8529411764705882),\n ('balance_explanation_test', 0.8333333333333334),\n ('balance_explanation_train', 0.8980392156862745),\n ('balance_model_train', nan),\n ('coverage', 0.0191),\n ('precision', 0.9552238805970149)}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 57
    }
   ],
   "source": [
    "# report all current metrics\n",
    "exp.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.,  4.,  9., ...,  0.,  0., 39.],\n       [ 1.,  4.,  9., ...,  0.,  2., 39.],\n       [ 1.,  4.,  9., ...,  0.,  2., 39.],\n       ...,\n       [ 1.,  4.,  9., ...,  0.,  0., 39.],\n       [ 1.,  4.,  9., ...,  0.,  2., 39.],\n       [ 1.,  4.,  9., ...,  0.,  0., 39.]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 58
    }
   ],
   "source": [
    "exp.get_neighborhood_instances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "inferred metrics: {'balance_data_test', 'balance_data_train', 'balance_model_train', 'inverse_coverage', 'balance_explanation_test', 'furthest_distance', 'coverage', 'precision', 'balance_data_dev', 'balance_explanation_dev', 'balance_explanation_train', 'balance_Explanation'}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# infer other possible metrics\n",
    "exp.infer_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}