{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71bb6105",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Comparing Explainers with Astrapia\n",
    "\n",
    "This notebook showcases the workflow of Astrapia: instantiating custom explainers and creating explanations from representative\n",
    "instances in the data in order to derive comparable metrics from the explanations.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172621c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "import astrapia as xb\n",
    "from astrapia import explainers, dataset\n",
    "from astrapia.comparator import ExplainerComparator\n",
    "from astrapia.visualization import print_metrics, load_metrics_from_json, print_properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf2ae63",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Initialization\n",
    "Retrieve dataset. \"adult\" and \"breast\" are already implemented in this framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf75369",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = dataset.load_csv_data('breast', root_path='../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf1e1a9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train machine learning classifier that the explainers are supposed to explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eecdaa8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=50, n_jobs=5)\n",
    "rf.fit(xb.utils.onehot_encode(data.data, data), data.target.to_numpy().reshape(-1))\n",
    "print('Train', sklearn.metrics.accuracy_score(data.target, rf.predict(xb.utils.onehot_encode(data.data, data))))\n",
    "print('Dev', sklearn.metrics.accuracy_score(data.target_dev, rf.predict(xb.utils.onehot_encode(data.data_dev, data))))\n",
    "print('Test',\n",
    "      sklearn.metrics.accuracy_score(data.target_test, rf.predict(xb.utils.onehot_encode(data.data_test, data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Retrieve classification probabilities from machine learning classifier."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "853462866c7a0cc0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4948403e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred_fn = lambda x: rf.predict_proba(xb.utils.onehot_encode(x, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7e03cb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Initialize explainers LIME and DLIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90727b3b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ex_lime = explainers.LimeExplainer(data, pred_fn, discretize_continuous=False)\n",
    "ex_dlime = explainers.DLimeExplainer(data, pred_fn, discretize_continuous=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37facba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Initialize explainers ANCHOR with different values for the precision of the explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ea7f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ex_anchors1 = explainers.AnchorsExplainer(data, pred_fn, 0.9)\n",
    "ex_anchors2 = explainers.AnchorsExplainer(data, pred_fn, 0.75)\n",
    "ex_anchors3 = explainers.AnchorsExplainer(data, pred_fn, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d15e63",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Initialize comparator of different explainers and add them to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c379e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "comp = ExplainerComparator()\n",
    "comp.add_explainer(ex_anchors1, 'ANCHORS 0.9')\n",
    "comp.add_explainer(ex_anchors2, 'ANCHORS 0.75')\n",
    "comp.add_explainer(ex_anchors3, 'ANCHORS 0.6')\n",
    "comp.add_explainer(ex_lime, 'LIME')\n",
    "comp.add_explainer(ex_dlime, 'DLIME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ca000",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Execution\n",
    "Provide the comparator with representative instances that the explainers will explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c4d300",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "comp.explain_representative(data, sampler='splime', count=5, pred_fn=pred_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2f0f7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Store metric data as json and assert that storing and reloading data does not modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416b0a99",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metric_data = comp.get_metric_data()\n",
    "comp.store_metrics()\n",
    "assert load_metrics_from_json('metrics.json') == metric_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0faeb24",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualization\n",
    "Output properties and metrics as tables or bar charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6953ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_metrics(metric_data, plot='table', show_metric_with_one_value=True)\n",
    "print_metrics(metric_data, plot='bar', show_metric_with_one_value=True)\n",
    "print_metrics(metric_data, explainer='ANCHORS 0.9')\n",
    "print_metrics(metric_data, plot=\"bar\", explainer='ANCHORS 0.9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d45ec2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_properties(metric_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29a0f126c1fc5ecf02a17e8e34dc1a7167bac14bfb1d0eed0b856ffb40d75faa"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
