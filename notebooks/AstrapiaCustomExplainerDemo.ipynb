{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Implementing your own explainer in Astrapia\n",
    "\n",
    "If you want to add your own Explainer to the framework, you can do so by following the workflow of this notebook. Note that\n",
    "the class definition of the Explainer is split into several individual parts in order to provide more explanations\n",
    "between the sections. When you define your own Explainer, you can of course do that as one code block that includes the whole class definition.\n",
    "\n",
    "As example, we define the explainer Anchors in this notebook which is already implemented in this framework. Check anchors.py for detailed documentation.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.ensemble\n",
    "from anchor import anchor_tabular\n",
    "\n",
    "import astrapia as xb\n",
    "from astrapia import Explainer\n",
    "from astrapia import explainers, dataset\n",
    "from astrapia.comparator import ExplainerComparator\n",
    "from astrapia.visualization import print_metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Extending the base Explainer class\n",
    "\n",
    "Define your class that extends the base explainer class and instantiate your Explainer. As parameters, it takes a dataset and the\n",
    "trained model that the Explainer will explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AnchorsExplainer(Explainer):\n",
    "    def __init__(self, data, predict_fn, min_precision=0.9):\n",
    "        self.anchors_dataset = self.transform_dataset(data.data, data)\n",
    "        self.min_precision = min_precision\n",
    "\n",
    "        self.explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "            self.anchors_dataset['class_names'],\n",
    "            self.anchors_dataset['feature_names'],\n",
    "            self.anchors_dataset['data'],\n",
    "            self.anchors_dataset['categorical_names'])\n",
    "        self.meta = data\n",
    "\n",
    "        def transformed_predict(data):\n",
    "            return predict_fn(self.inverse_transform_dataset({'data': data}, self.meta))[:, 1] > 0.5\n",
    "\n",
    "        self.predictor = transformed_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Provide functions to (1) transform the given dataset into one that is readable by your explainer and (2) transform the\n",
    "given dataset into a format that can be used by the model to predict the label of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AnchorsExplainer(AnchorsExplainer):\n",
    "    def transform_dataset(self, data: pd.DataFrame, meta: xb.Dataset) -> any:\n",
    "        result = {\n",
    "            'labels': (meta.target == meta.target_names[-1]).astype(int).to_numpy().reshape((-1,)),\n",
    "            'class_names': meta.target_names,\n",
    "            'ordinal_features': [i for i, label in (enumerate(meta.feature_names)) if label not\n",
    "                                 in meta.categorical_features.keys()],\n",
    "            'categorical_features': [i for i, label in (enumerate(meta.feature_names)) if label\n",
    "                                     in meta.categorical_features.keys()],\n",
    "            'categorical_names': {idx: [str(x) for x in meta.categorical_features[feature]] for idx, feature\n",
    "                                  in enumerate(meta.feature_names) if feature in meta.categorical_features},\n",
    "            'feature_names': meta.feature_names,\n",
    "            'data': data.to_numpy()\n",
    "        }\n",
    "\n",
    "        for feature_idx in result['categorical_features']:\n",
    "            feature_map = {feature: idx for idx, feature in enumerate(result['categorical_names'][feature_idx])}\n",
    "            result['data'][:, feature_idx] = np.vectorize(lambda x: feature_map[str(x)])(result['data'][:, feature_idx])\n",
    "\n",
    "        return result\n",
    "\n",
    "    def inverse_transform_dataset(self, data: any, meta: xb.Dataset) -> pd.DataFrame:\n",
    "        df = pd.DataFrame(data['data'], columns=meta.feature_names)\n",
    "        for feature_idx in [i for i, label in (enumerate(meta.data.keys())) if\n",
    "                            label in meta.categorical_features.keys()]:\n",
    "            df[meta.feature_names[feature_idx]] = df[meta.feature_names[feature_idx]].map(\n",
    "                lambda entry: meta.categorical_features[meta.feature_names[feature_idx]][entry])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Implement the explain_instance function which uses the functionality of your explainer to create an explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AnchorsExplainer(AnchorsExplainer):\n",
    "    def explain_instance(self, instance):\n",
    "        instance = self.transform_dataset(instance, self.meta)\n",
    "        self.explanation = self.explainer.explain_instance(instance['data'][0], self.predictor,\n",
    "                                                           threshold=self.min_precision)\n",
    "        self.instance = instance['data'][0]\n",
    "        return self.explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Optionally, define named properties for your explainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AnchorsExplainer(AnchorsExplainer):\n",
    "    @xb.prop\n",
    "    def shape(self):\n",
    "        return 'Hyperrectangle'\n",
    "\n",
    "    @xb.prop\n",
    "    def name(self):\n",
    "        return 'Anchors'\n",
    "\n",
    "    @xb.prop\n",
    "    def instancing(self):\n",
    "        return 'binary'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Optionally, define helper function (to retrieve instances in the local neighborhood)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AnchorsExplainer(AnchorsExplainer):\n",
    "    @xb.utility\n",
    "    def get_fit_anchor(self, dataset):\n",
    "        \"\"\"\n",
    "        Returns indices of data elements that are in the explanation neighborhood\n",
    "\n",
    "        :param dataset: provided dataset\n",
    "        :return: indices as numpy array\n",
    "        \"\"\"\n",
    "        indices_categorical = np.where(np.all(dataset[:, self.explanation.features()] ==\n",
    "                                              self.instance[self.explanation.features()], axis=1))[0]\n",
    "\n",
    "        if np.size(indices_categorical) > 0:\n",
    "            return indices_categorical\n",
    "\n",
    "        # derive neighborhood from the name of the explanation\n",
    "        try:\n",
    "            index_lists = []\n",
    "            for feature, name in zip(self.explanation.features(), self.explanation.names()):\n",
    "                if \">=\" in name:\n",
    "                    index_lists.append(np.where(dataset[:, feature] >= float(name[name.index('>= ') + 3:])))\n",
    "                elif \"<=\" in name:\n",
    "                    index_lists.append(np.where(dataset[:, feature] <= float(name[name.index('<= ') + 3:])))\n",
    "                elif \">\" in name:\n",
    "                    index_lists.append(np.where(dataset[:, feature] > float(name[name.index('> ') + 2:])))\n",
    "                elif \"<\" in name:\n",
    "                    index_lists.append(np.where(dataset[:, feature] < float(name[name.index('< ') + 2:])))\n",
    "                elif \"=\" in name:\n",
    "                    index_lists.append(np.where(dataset[:, feature] == name[name.index('\" ') + 2:]))\n",
    "\n",
    "            # intersect different sublits of indices\n",
    "            indices_numerical = index_lists[0]\n",
    "            for i in range(1, len(index_lists)):\n",
    "                indices_numerical = np.intersect1d(indices_numerical, index_lists[i])\n",
    "\n",
    "            if np.size(indices_numerical) < np.size(indices_categorical):\n",
    "                return indices_categorical\n",
    "            else:\n",
    "                return indices_numerical\n",
    "        except:\n",
    "            return indices_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Implement metrics that can be derived from your explanation. Check the documentation to find the definition of multiple\n",
    "metrics if you want to compare the performance of your explainer with the ones that have already been implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AnchorsExplainer(AnchorsExplainer):\n",
    "    @xb.metric\n",
    "    def coverage(self):\n",
    "        \"\"\"\n",
    "        The relative amount of data elements that are in the area of the explanation\n",
    "\n",
    "        :return: the coverage value\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'explanation'):\n",
    "            return self.explanation.coverage()\n",
    "\n",
    "    @xb.metric\n",
    "    def coverage_absolute(self):\n",
    "        \"\"\"\n",
    "        Number of instances within the neighbourhood.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'explanation'):\n",
    "            try:\n",
    "                return self.get_fit_anchor(self.anchors_dataset['data']).shape[0]\n",
    "            except AttributeError:\n",
    "                return 0\n",
    "\n",
    "    @xb.metric\n",
    "    def accuracy(self):\n",
    "        \"\"\"\n",
    "        Relative amount of data elements in explanation neighborhood or given dataset that have the same explanation\n",
    "        label as the label assigned by the ML model\n",
    "\n",
    "        :return: the accuracy value\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'explanation'):\n",
    "            explanation_label = self.explanation.exp_map[\"prediction\"]\n",
    "            neighborhood = self.anchors_dataset['data'][self.get_fit_anchor(self.anchors_dataset['data'])]\n",
    "            if len(neighborhood) > 0:\n",
    "                ml_pred = self.predictor(neighborhood)\n",
    "                return np.count_nonzero(ml_pred == explanation_label) / len(neighborhood)\n",
    "            else:\n",
    "                return np.nan\n",
    "\n",
    "    @xb.metric\n",
    "    def accuracy_global(self):\n",
    "        \"\"\"\n",
    "        The ML-accuracy of the explanation when applied to the whole dataset (not just the area of the explanation)\n",
    "\n",
    "        :return: the precision value\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'explanation'):\n",
    "            return self.explanation.precision()\n",
    "\n",
    "    @xb.metric\n",
    "    def balance_explanation(self):\n",
    "        \"\"\"\n",
    "        Relative amount of data elements in the explanation neighborhood that had an assigned label value of 1\n",
    "        (by the explanation)\n",
    "\n",
    "        :return: the balance value\n",
    "        \"\"\"\n",
    "        # balance is always 0 or 1 because Anchors creates a neighborhood where all elements are supposed to have\n",
    "        # the same label as the one that was used to instantiate the explanation\n",
    "        if hasattr(self, 'explanation'):\n",
    "            return int(self.explanation.exp_map[\"prediction\"])\n",
    "\n",
    "    @xb.metric\n",
    "    def balance_model(self):\n",
    "        \"\"\"\n",
    "        Relative amount of data elements in the neighborhood of the explanation that had a label value of 1 assigned\n",
    "        by the classification model\n",
    "\n",
    "        :return: the balance value\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'explanation'):\n",
    "            pred = self.predictor(self.anchors_dataset['data'])\n",
    "            neighborhood = pred[self.get_fit_anchor(self.anchors_dataset['data'])]\n",
    "            if neighborhood.size > 0:\n",
    "                return np.mean(neighborhood)\n",
    "            else:\n",
    "                return np.nan\n",
    "\n",
    "    @xb.metric\n",
    "    def balance_data(self):\n",
    "        \"\"\"\n",
    "        Relative amount of data elements in the neighborhood of the explanation with a label value of 1\n",
    "\n",
    "        :return: the balance value\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'explanation'):\n",
    "            neighborhood = self.anchors_dataset['labels'][self.get_fit_anchor(self.anchors_dataset['data'])]\n",
    "            if neighborhood.size > 0:\n",
    "                return np.mean(neighborhood)\n",
    "            else:\n",
    "                return np.nan\n",
    "\n",
    "    @xb.metric\n",
    "    def area_relative(self):\n",
    "        \"\"\"\n",
    "        Relative amount of feature space over all features n that is specified by the explanation.\n",
    "        area = Product[i=1->n] fi, f: 1 if feature is not in explanation, else 1/m, m: deminsionality of feature\n",
    "\n",
    "        :return: the area value\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'explanation'):\n",
    "            array = np.amax(self.anchors_dataset['data'], axis=0)[self.explanation.features()]\n",
    "            array = array + 1\n",
    "            return np.prod(1 / array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Usage\n",
    "\n",
    "Retrieve a dataset and train a machine learning classifier that should be explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = dataset.load_csv_data('adult', root_path='../data')\n",
    "\n",
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=50, n_jobs=5)\n",
    "rf.fit(xb.utils.onehot_encode(data.data, data), data.target.to_numpy().reshape(-1))\n",
    "pred_fn = lambda x: rf.predict_proba(xb.utils.onehot_encode(x, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Instantiate your explainer and a preimplemented one to have something to compare it with. Add them to the comparator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ex_anchors_custom = AnchorsExplainer(data, pred_fn)\n",
    "ex_lime = explainers.LimeExplainer(data, pred_fn, discretize_continuous=False)\n",
    "\n",
    "comp = ExplainerComparator()\n",
    "comp.add_explainer(ex_anchors_custom, \"ANCHORS_CUSTOM\")\n",
    "comp.add_explainer(ex_lime, \"LIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Explain instances and visualize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "comp.explain_representative(data, sampler='random', count=2, pred_fn=pred_fn)\n",
    "print_metrics(comp.get_metric_data(), plot=\"bar\", show_metric_with_one_value=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
