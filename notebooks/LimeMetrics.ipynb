{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "# util\n",
    "from xaibenchmark import load_adult as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = la.load_csv_data('adult', root_path='../data')\n",
    "\n",
    "def preprocess(*data_df): \n",
    "    def process_single(df):\n",
    "        \n",
    "        cat_df = pd.get_dummies(df, columns=data.categorical_features.keys())\n",
    "        missing_cols = {cat+'_'+str(attr) for cat in data.categorical_features \\\n",
    "                        for attr in data.categorical_features[cat]} - set(cat_df.columns)\n",
    "        for c in missing_cols:\n",
    "            cat_df[c] = 0\n",
    "            \n",
    "        cont_idx = list(set(data.data.keys()) - set(data.categorical_features.keys()))\n",
    "        cat_idx = [cat+'_'+str(attr) for cat in data.categorical_features \\\n",
    "                   for attr in data.categorical_features[cat]]\n",
    "        idx = cont_idx + cat_idx\n",
    "        return cat_df[idx]\n",
    "        \n",
    "    # Preprocess function for one-hot encoding categorical data\n",
    "    return [process_single(df) for df in data_df]\n",
    "\n",
    "train, dev, test = preprocess(data.data, data.data_dev, data.data_test)\n",
    "labels_train, labels_dev, labels_test = data.target, data.target_dev, data.target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(n_estimators=500)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n",
    "rf.fit(train, labels_train.to_numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = labels_dev.to_numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.89      0.93      0.91      7400\n",
      "        >50K       0.74      0.62      0.68      2368\n",
      "\n",
      "    accuracy                           0.86      9768\n",
      "   macro avg       0.81      0.78      0.79      9768\n",
      "weighted avg       0.85      0.86      0.85      9768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report')\n",
    "print('{:->60}'.format(''))\n",
    "print(sklearn.metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xaibenchmark as xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LimeExplainer(xb.Explainer):\n",
    "    \n",
    "    def __init__(self, train_data, train_labels, model, feature_names, target_names, positive_label, discretize_continuous=True):\n",
    "        \n",
    "        self.explainer = lime.lime_tabular.LimeTabularExplainer(train_data, feature_names=feature_names,\n",
    "                                                   class_names=target_names,\n",
    "                                                   discretize_continuous=discretize_continuous)\n",
    "        self.train = train_data\n",
    "        self.train_labels = train_labels\n",
    "        self.positive_label = positive_label\n",
    "        self.model = model\n",
    "        self.kernel_width = np.sqrt(train_data.shape[1]) * .75\n",
    "        \n",
    "    def explain_instance(self, instance, predictor, num_features=10):\n",
    "        self.explanation = self.explainer.explain_instance(instance, predictor, num_features=num_features)\n",
    "        self.instance = instance\n",
    "        return self.explanation\n",
    "    \n",
    "    @xb.metric\n",
    "    def area(self):\n",
    "        kernel_width = np.sqrt(self.train.shape[1]) * .75\n",
    "        kernel_dimension = self.train.shape[1]\n",
    "        return (kernel_width * np.sqrt(2*np.pi))**kernel_dimension\n",
    "    \n",
    "    @xb.metric\n",
    "    def coverage(self):\n",
    "        weighted_instances = self.get_weighted_instances()\n",
    "        return sum([weight for _,weight in weighted_instances]) / len(weighted_instances)\n",
    "    \n",
    "    @xb.metric\n",
    "    def furthest_distance(self):\n",
    "        kernel_width = np.sqrt(self.train.shape[1]) * .75\n",
    "        def kernel(distance):\n",
    "            return np.sqrt(np.exp(-distance**2/kernel_width**2))\n",
    "        training_instances = self.train.to_numpy()\n",
    "        distance_instances = (self.distance(self.instance, instance) for instance in training_instances)\n",
    "        weighted_distances = (distance * kernel(distance) for distance in distance_instances)\n",
    "        return sum(weighted_distances)\n",
    "\n",
    "    @xb.metric\n",
    "    def accuracy(self):\n",
    "        \"\"\" the fraction of the same predicted label count between ML model and the explainer \"\"\"\n",
    "        y_pred = self.get_model_prediction()\n",
    "        y_true = self.train_labels.to_numpy().reshape(-1)\n",
    "        fraction = sum(y_true == y_pred)\n",
    "        return fraction / len(y_true)\n",
    "\n",
    "    @xb.metric\n",
    "    def balance(self):\n",
    "        \"\"\" the proportion of positive and negative labels from the model's output \"\"\"\n",
    "        y_pred = self.get_model_prediction()\n",
    "        pos = sum(y_pred == self.positive_label)\n",
    "        neg = len(y_pred) - pos\n",
    "        return pos / neg\n",
    "\n",
    "    @xb.utility\n",
    "    def distance(self, x, y):\n",
    "        return np.linalg.norm(x-y)\n",
    "    \n",
    "    @xb.utility\n",
    "    def get_weighted_instances(self):     \n",
    "        if hasattr(self, 'explanation'):\n",
    "            kernel_width = np.sqrt(self.train.shape[1]) * .75\n",
    "            def kernel(distance):\n",
    "                return np.sqrt(np.exp(-distance**2/kernel_width**2))\n",
    "            return [(instance, kernel(self.distance(self.instance, instance))) for instance in self.train.to_numpy()]\n",
    "        return []\n",
    "    \n",
    "    @xb.utility\n",
    "    def get_explained_instance(self):\n",
    "        return self.instance\n",
    "    \n",
    "    @xb.utility\n",
    "    def get_training_data(self):\n",
    "        return self.train\n",
    "\n",
    "    @xb.utility\n",
    "    def get_model_prediction(self):\n",
    "        return self.model.predict(self.train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = LimeExplainer(train, labels_train, rf, train.keys(), data.target_names, \">50K\", discretize_continuous=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<lime.explanation.Explanation at 0x7f83bd2aabb0>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.explain_instance(test.iloc[1], rf.predict_proba, num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{('accuracy', 0.99995612688106),\n ('area', 2.589477453233665e+139),\n ('balance', 0.3159170948559552),\n ('coverage', 1.5792597810605184e-05),\n ('furthest_distance', 5.169826688431765)}"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferred metrics: {'coverage', 'accuracy', 'area_hc_normalised', 'balance', 'area', 'inverse_coverage', 'furthest_distance'}\n"
     ]
    }
   ],
   "source": [
    "exp.infer_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{('accuracy', 0.99995612688106),\n ('area', 2.589477453233665e+139),\n ('area_hc_normalised', 19.537233873073223),\n ('balance', 0.3159170948559552),\n ('coverage', 1.5792597810605184e-05),\n ('furthest_distance', 5.169826688431765),\n ('inverse_coverage', 63320.8045941923)}"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "8362"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}